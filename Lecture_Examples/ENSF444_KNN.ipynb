{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# K-Nearest Neighbors\n",
        "\n",
        "* K-nearest neighbors (K-NN) predicts the classification of new data sample(s) depending on the proximity of the new data sample(s) to the existing data\n",
        "\n",
        "* K represents the number of neighbors considered to determine the label for the new data sample\n",
        "\n",
        "* The predicted label is based on a voting method, so an odd number of neighbors is preferred to ensure there are no ties\n"
      ],
      "metadata": {
        "id": "KVD8Pep_jc_t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example: Synthetic Dataset\n",
        "\n",
        "<font color='Blue'><b>Example</b></font>: The synthetic dataset is generated using the `make_blobs` function from scikit-learn, designed for creating artificial datasets for various machine learning experiments. This particular dataset consists of the following characteristics:\n",
        "\n",
        "- **Number of Samples:** 2000\n",
        "- **Number of Features:** 2\n",
        "- **Number of Classes:** 4\n",
        "- **Random Seed (random_state):** 0\n",
        "- **Cluster Standard Deviation (cluster_std):** 1.0\n",
        "\n",
        "**Features:**\n",
        "- The dataset contains 2000 data points, each described by a pair of feature values. These features are represented as 'Feature 1' and 'Feature 2'.\n",
        "\n",
        "**Outcome (Target Variable):**\n",
        "- The dataset also includes a target variable called 'Outcome.' This variable assigns each data point to one of two distinct classes, identified as 'Class 0',  'Class 1',  'Class 2', and 'Class 3'."
      ],
      "metadata": {
        "id": "AJWFlGgL5MHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_blobs\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "# Generate synthetic data\n",
        "X, y = make_blobs(n_samples=2000, centers=4, random_state=0, cluster_std=1.0)\n",
        "\n",
        "# Create a DataFrame\n",
        "Data = pd.DataFrame(data=X, columns=['Feature %i' % (i + 1) for i in range(2)])\n",
        "Data['Outcome'] = y\n",
        "\n",
        "display(Data)\n",
        "\n",
        "plt.style.use('https://raw.githubusercontent.com/HatefDastour/ENSF444/main/Files/mystyle.mplstyle')\n",
        "\n",
        "# Create a scatter plot using Seaborn\n",
        "fig, ax = plt.subplots(1, 1, figsize=(9.5, 7))\n",
        "\n",
        "colors = [\"#f5645a\", \"#b781ea\", '#B2FF66', '#0096ff']\n",
        "edge_colors = ['#8A0002', '#3C1F8B','#6A993D', '#2e658c']\n",
        "markers = ['o', 's', 'd', '^']\n",
        "cmap_ = ListedColormap(colors)\n",
        "\n",
        "# Scatter plot of data points\n",
        "for num in np.unique(y):\n",
        "    ax.scatter(X[:, 0][y == num], X[:, 1][y == num], c=colors[num],\n",
        "                s=40, edgecolors= edge_colors[num], marker=markers[num], label=str(num))\n",
        "\n",
        "ax.set(xlim=[-6, 6], ylim=[-2, 12])\n",
        "ax.legend()\n",
        "ax.set_title('Synthetic Dataset', weight = 'bold', fontsize = 16)\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "J-CphJh55OKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.25, random_state=0, stratify=y)"
      ],
      "metadata": {
        "id": "u6vqb9dR5S-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.25, random_state=0, stratify=y)\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def _dist_plot(ax, y, CM=plt.cm.tab20c.colors, title=False):\n",
        "    \"\"\"\n",
        "    Generate a pie chart illustrating the distribution of categories.\n",
        "\n",
        "    Parameters:\n",
        "    - ax: Axes object to plot on.\n",
        "    - y: Input data for which the distribution is to be visualized.\n",
        "    - label_mapping: Dictionary mapping category indices to labels.\n",
        "    - CM: Color map for the pie chart.\n",
        "    - title: Title for the plot. Set to False to omit.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    # Prepare data for the pie chart\n",
        "    df = pd.Series(y).value_counts().to_frame('Count')\n",
        "\n",
        "    # Create the pie chart\n",
        "    wedges, texts, autotexts = ax.pie(df['Count'],\n",
        "                                      autopct='%1.1f%%', startangle=140,\n",
        "                                      colors=CM,\n",
        "                                      explode=[0, 0, 0, 0.1],\n",
        "                                      shadow=True, wedgeprops={'edgecolor': 'whitesmoke'})\n",
        "    # Set title and ensure equal aspect ratio for a circular pie chart\n",
        "    if title:\n",
        "        _ = ax.set_title(title, fontsize=16, weight='bold')\n",
        "    _ = ax.axis('equal')\n",
        "\n",
        "    # Highlight the labels with annotations\n",
        "    for text, autotext in zip(texts, autotexts):\n",
        "        text.set_fontsize(12)\n",
        "        text.set_fontweight('bold')\n",
        "        autotext.set_fontsize(12)\n",
        "        autotext.set_fontweight('bold')\n",
        "\n",
        "\n",
        "# Create the figure and axes\n",
        "fig, ax = plt.subplots(1, 2, figsize=(9, 4.5))\n",
        "_dist_plot(ax[0], y_train, CM = plt.cm.Set3.colors)\n",
        "_ = ax[0].set_title(f'Train Set (Size = {len(X_train)})', fontsize=12, weight='bold', color='Green')\n",
        "_dist_plot(ax[1], y_test, CM = plt.cm.Set3.colors)\n",
        "_ = ax[1].set_title(f'Test Set (Size = {len(X_test)})', fontsize=12, weight='bold', color='Blue')\n",
        "_ = fig.suptitle('Distribution of Categories', fontsize=16, weight='bold')\n",
        "\n",
        "# Adjust layout and display the plot\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "DHZrFw_a7I34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 1: n_neighbors = 5"
      ],
      "metadata": {
        "id": "sr3oTGtjaO8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary class from scikit-learn\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Create a KNN classifier with 5 neighbors\n",
        "KKN = KNeighborsClassifier(n_neighbors = 5)\n",
        "\n",
        "# Fit the KNN classifier to the training data\n",
        "KKN.fit(X_train, y_train)\n",
        "\n",
        "def _gen_cr(model, X, y):\n",
        "    y_pred = model.predict(X)\n",
        "    Results = pd.DataFrame(classification_report(y, y_pred,\n",
        "                                             output_dict=True)).T\n",
        "    display(Results.style.format(precision = 3))\n",
        "\n",
        "print('\\nTrain Data:')\n",
        "_gen_cr(KKN, X_train, y_train)\n",
        "\n",
        "print('\\nTest Data:')\n",
        "_gen_cr(KKN, X_test, y_test)\n",
        "\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.inspection import DecisionBoundaryDisplay\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(9.5, 5.5), sharey = False)\n",
        "\n",
        "# Create a loop for train and test sets\n",
        "for i, (X_set, y_set, title) in enumerate([(X_train, y_train, 'Train Set'), (X_test, y_test, 'Test Set')]):\n",
        "    # Plot decision boundaries\n",
        "    DecisionBoundaryDisplay.from_estimator(KKN, X_set, cmap=cmap_, ax=ax[i],\n",
        "                                           alpha = 0.3, eps = 2,\n",
        "                                           grid_resolution= 300,\n",
        "                                           response_method=\"predict\",\n",
        "                                           plot_method=\"pcolormesh\",\n",
        "                                           xlabel='Feature 1', ylabel='Feature 2',\n",
        "                                           shading=\"auto\")\n",
        "    ax[i].set(xlim =[-6, 6], ylim = [-3, 12])\n",
        "    ax[i].set_aspect('equal')\n",
        "    # Scatter plot of data points\n",
        "    for num in np.unique(y):\n",
        "        ax[i].scatter(X[:, 0][y == num], X[:, 1][y == num], c=colors[num],\n",
        "                    s=40, edgecolors= edge_colors[num], marker=markers[num], label=str(num))\n",
        "\n",
        "    ax[i].legend(title=\"Outcome\")\n",
        "    ax[i].set_title(f'{title} - KNN\\n(neighbors = 5)', fontweight='bold', fontsize=14)\n",
        "    ax[i].grid(False)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "\n",
        "def plot_cm(model, X_train, X_test, y_train, y_test, class_names, figsize=(7, 4), normalize = False):\n",
        "    # Create a figure and axes for displaying confusion matrices side by side\n",
        "    fig, ax = plt.subplots(1, 2, figsize=figsize)\n",
        "\n",
        "    datasets = [(X_train, y_train, 'Train'), (X_test, y_test, 'Test')]\n",
        "\n",
        "    for i in range(2):\n",
        "        X, y, dataset_name = datasets[i]\n",
        "\n",
        "        # Compute confusion matrix for the dataset predictions\n",
        "        cm = confusion_matrix(y, model.predict(X))\n",
        "        if normalize:\n",
        "            cm = np.round(cm/cm.sum(axis = 1), 2)\n",
        "            fig.suptitle('Confusion Matrices (Normalized)', fontsize=16, weight = 'bold')\n",
        "        else:\n",
        "            fig.suptitle('Confusion Matrices', fontsize=16, weight = 'bold')\n",
        "        # Create a ConfusionMatrixDisplay and plot it on the respective axis\n",
        "        cm_display = ConfusionMatrixDisplay(cm, display_labels=class_names)\\\n",
        "                        .plot(ax=ax[i],\n",
        "                              im_kw=dict(cmap='Greens' if dataset_name == 'Train' else 'Blues'),\n",
        "                              text_kw={\"size\": 16}, colorbar=False)\n",
        "        ax[i].set_title(f'{dataset_name} Data')\n",
        "        ax[i].grid(False)\n",
        "\n",
        "    # Adjust the layout for better spacing\n",
        "    plt.tight_layout()\n",
        "\n",
        "plot_cm(KKN, X_train, X_test, y_train, y_test, np.unique(y).astype('str'), figsize=(8, 4))\n",
        "plot_cm(KKN, X_train, X_test, y_train, y_test, np.unique(y).astype('str'), figsize=(8, 4), normalize=True)\n",
        "\n",
        "\n",
        "# Calculate accuracy using accuracy_score\n",
        "KKN_accuracy = KKN.score(X_train, y_train)\n",
        "print(f\"KKN Classifier Accuracy (Train): {KKN_accuracy:.4f}\")\n",
        "KKN_accuracy = KKN.score(X_test, y_test)\n",
        "print(f\"KKN Classifier Accuracy (Test): {KKN_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "DAlbQVFT-rrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 2"
      ],
      "metadata": {
        "id": "9QHBmB0YaSIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming X_train, y_train, X_test, y_test are defined\n",
        "\n",
        "# Varying values of n_neighbors\n",
        "n_neighbors_values = [1, 3, 5, 7, 10, 15, 20, 30, 50]\n",
        "\n",
        "# Lists to store accuracy scores\n",
        "train_accuracy_scores = []\n",
        "test_accuracy_scores = []\n",
        "\n",
        "# Iterate over different values of n_neighbors\n",
        "for n_neighbors in n_neighbors_values:\n",
        "    # Create a KNN classifier with the current n_neighbors\n",
        "    KKN = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "\n",
        "    # Fit the classifier to the training data\n",
        "    KKN.fit(X_train, y_train)\n",
        "\n",
        "    # Calculate accuracy scores and append to the lists\n",
        "    train_accuracy = KKN.score(X_train, y_train)\n",
        "    test_accuracy = KKN.score(X_test, y_test)\n",
        "\n",
        "    train_accuracy_scores.append(train_accuracy)\n",
        "    test_accuracy_scores.append(test_accuracy)\n",
        "\n",
        "# Create a fixed figure and axes\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "\n",
        "# Plotting the accuracy scores\n",
        "ax.plot(n_neighbors_values, train_accuracy_scores, label='Train Accuracy', marker='o', color='green')\n",
        "ax.plot(n_neighbors_values, test_accuracy_scores, label='Test Accuracy', marker='o', color='blue')\n",
        "\n",
        "ax.set_title('Accuracy Scores for Different Values of n_neighbors')\n",
        "ax.set_xlabel('n_neighbors')\n",
        "ax.set_ylabel('Accuracy Score')\n",
        "ax.legend()\n",
        "ax.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hqx3ioMSaUFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='Blue'><b>Example</b></font>. The Auto MPG dataset retrieved from the [UCI Machine Learning Repository](http://archive.ics.uci.edu/dataset/9/auto+mpg)."
      ],
      "metadata": {
        "id": "sj7V4t-fc6rq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from ucimlrepo import fetch_ucirepo\n",
        "except ImportError:\n",
        "    !pip3 install -U ucimlrepo\n",
        "    from ucimlrepo import fetch_ucirepo\n",
        "import numpy as np\n",
        "\n",
        "# fetch dataset\n",
        "auto_mpg = fetch_ucirepo(name = 'Auto MPG')\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = auto_mpg.data.features\n",
        "y = auto_mpg.data.targets\n",
        "\n",
        "# drop rows with missing values from X\n",
        "X = X.dropna(axis=0, how='any')\n",
        "\n",
        "# align X and y by index\n",
        "X, y = X.align(y, join='inner', axis=0)\n",
        "\n",
        "# ln(mpg)\n",
        "y = np.log(y['mpg'])\n",
        "y.name = 'ln(mpg)'\n",
        "X = X['horsepower'].values.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "Qjqj8f3jaVUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "\n",
        "# Create a DataFrame to display the sizes of the training and testing sets\n",
        "set_size_df = pd.DataFrame({'Size': [len(X_train), len(X_test)]}, index=['Train', 'Test'])\n",
        "display(set_size_df.T)"
      ],
      "metadata": {
        "id": "Qmh7OiLUc8Zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import neighbors\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "T = np.linspace(X.min(), X.max(), 200).reshape(-1, 1)\n",
        "\n",
        "n_neighbors = 10\n",
        "\n",
        "# Create a figure and axes for subplots\n",
        "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(14, 6))\n",
        "axes = axes.ravel()\n",
        "\n",
        "# Define common style parameters\n",
        "scatter_params = {'s': 40, 'ec': 'k', 'lw': 0.5, 'alpha': 0.5}\n",
        "plot_params = {'color': 'navy', 'label': 'Predicted ln(MPG)', 'lw': 2}\n",
        "\n",
        "for i, (ax, n_neighbors) in enumerate(zip(axes, [3, 5, 10, 15])):\n",
        "    # Create KNeighborsRegressor\n",
        "    knn = neighbors.KNeighborsRegressor(n_neighbors = n_neighbors, weights= 'uniform')\n",
        "    _ = knn.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_ = knn.predict(T)\n",
        "\n",
        "    # Scatter plot for input features\n",
        "    ax.scatter(X_train, y_train, label = 'Train Data',  c = '#6aa84f', **scatter_params)\n",
        "    ax.scatter(X_test, y_test, label = 'Test Data',  c = '#f44336', **scatter_params)\n",
        "\n",
        "    # Line plot for predictions\n",
        "    ax.plot(T, y_, **plot_params)\n",
        "\n",
        "    # Calculate Mean Squared Error (MSE)\n",
        "    mse_train = mean_squared_error(y_train, knn.predict(X_train))\n",
        "    mse_test = mean_squared_error(y_test, knn.predict(X_test))\n",
        "\n",
        "    # Set common style parameters\n",
        "    ax.axis(\"tight\")\n",
        "    ax.legend(fontsize=14)\n",
        "    ax.set_title(f\"KNeighborsRegressor (n_neighbors = {n_neighbors})\", weight='bold')\n",
        "    ax.set(xlim=[25, 250], ylim=[2, 4])\n",
        "\n",
        "    # Display MSE at the bottom left of each plot\n",
        "    ax.text(0.02, 0.08, f'MSE (Train): {mse_train:.4f}\\nMSE (Test): {mse_test:.4f}',\n",
        "            transform=ax.transAxes, fontsize=12, weight='bold',\n",
        "            bbox=dict(facecolor='Whitesmoke', alpha=0.7))\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "e5WfKIWGdGno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import neighbors\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "n_neighbors = 10\n",
        "\n",
        "# Create a figure and axes for subplots\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(9.5, 6))\n",
        "\n",
        "for i, (ax, weights) in enumerate(zip(axes, [\"uniform\", \"distance\"])):\n",
        "    # Create KNeighborsRegressor\n",
        "    knn = neighbors.KNeighborsRegressor(n_neighbors = n_neighbors, weights= weights)\n",
        "    _ = knn.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_ = knn.predict(T)\n",
        "\n",
        "    # Scatter plot for input features\n",
        "    ax.scatter(X_train, y_train, label = 'Train Data',  c = '#6aa84f', **scatter_params)\n",
        "    ax.scatter(X_test, y_test, label = 'Test Data',  c = '#f44336', **scatter_params)\n",
        "\n",
        "    # Line plot for predictions\n",
        "    ax.plot(T, y_, **plot_params)\n",
        "\n",
        "    # Calculate Mean Squared Error (MSE)\n",
        "    mse_train = mean_squared_error(y_train, knn.predict(X_train))\n",
        "    mse_test = mean_squared_error(y_test, knn.predict(X_test))\n",
        "\n",
        "    # Set common style parameters\n",
        "    ax.axis(\"tight\")\n",
        "    ax.legend(fontsize=14)\n",
        "    ax.set_title(f\"KNeighborsRegressor (n_neighbors = {n_neighbors} and weights = '{weights}')\", weight='bold')\n",
        "    ax.set(xlim=[25, 250], ylim=[2, 4])\n",
        "\n",
        "    # Display MSE at the bottom left of each plot\n",
        "    ax.text(0.02, 0.08, f'MSE (Train): {mse_train:.4f}\\nMSE (Test): {mse_test:.4f}',\n",
        "            transform=ax.transAxes, fontsize=12, weight='bold',\n",
        "            bbox=dict(facecolor='Whitesmoke', alpha=0.7))\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "oY-Vck3wdsAF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}