{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Boosted Decision Trees\n",
        "\n",
        "## Gradient Boosting Regressor\n",
        "\n",
        "<font color='Blue'><b>Example</b></font>. The Auto MPG dataset retrieved from the [UCI Machine Learning Repository](http://archive.ics.uci.edu/dataset/9/auto+mpg)."
      ],
      "metadata": {
        "id": "dJZHQyvm58DI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fexQXK454w0"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from ucimlrepo import fetch_ucirepo\n",
        "except ImportError:\n",
        "    !pip3 install -U ucimlrepo\n",
        "    from ucimlrepo import fetch_ucirepo\n",
        "import numpy as np\n",
        "\n",
        "# fetch dataset\n",
        "auto_mpg = fetch_ucirepo(name = 'Auto MPG')\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = auto_mpg.data.features\n",
        "y = auto_mpg.data.targets\n",
        "\n",
        "# drop rows with missing values from X\n",
        "X = X.dropna(axis=0, how='any')\n",
        "\n",
        "# align X and y by index\n",
        "X, y = X.align(y, join='inner', axis=0)\n",
        "\n",
        "# ln(mpg)\n",
        "y = np.log(y['mpg'])\n",
        "y.name = 'ln(mpg)'\n",
        "print('X:')\n",
        "display(X)\n",
        "print('\\ny:')\n",
        "print(y)\n",
        "print('\\nInfo:')\n",
        "X.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "\n",
        "# Create a DataFrame to display the sizes of the training and testing sets\n",
        "set_size_df = pd.DataFrame({'Size': [len(X_train), len(X_test)]}, index=['Train', 'Test'])\n",
        "display(set_size_df.T)"
      ],
      "metadata": {
        "id": "mR4t8aut8MVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import xgboost as xgb\n",
        "from sklearn import metrics\n",
        "try:\n",
        "  import sklearnex\n",
        "except ImportError:\n",
        "  !pip install pip install scikit-learn-intelex\n",
        "  import sklearnex\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "sklearnex.patch_sklearn()\n",
        "\n",
        "random_state = 0\n",
        "\n",
        "plt.style.use('https://raw.githubusercontent.com/HatefDastour/ENSF444/main/Files/mystyle.mplstyle')\n",
        "\n",
        "# Create a figure and subplots\n",
        "fig, ax = plt.subplots(2, 2, figsize=(9.5, 9.5))\n",
        "feature_set_labels = [\"\"\"Using sklearn's\\nGradientBoostingRegressor\"\"\",\n",
        "                      \"\"\"Using xgboost's\\nXGBRegressor\"\"\"]\n",
        "\n",
        "reg_gb = GradientBoostingRegressor(random_state = random_state, n_estimators = 100, learning_rate = 0.1)\n",
        "reg_gb.fit(X_train, y_train)\n",
        "\n",
        "reg_xgb = xgb.XGBRegressor(random_state = random_state, n_estimators = 100, learning_rate = 0.1)\n",
        "reg_xgb.fit(X_train, y_train)\n",
        "\n",
        "# Loop through different feature sets\n",
        "for i, reg in enumerate([reg_gb, reg_xgb]):\n",
        "    # Train set\n",
        "    y_pred_train = reg.predict(X_train)\n",
        "    ax[i, 0].scatter(y_train, y_pred_train,\n",
        "                     facecolors='#a7e0f7', edgecolors='#191970', alpha=0.8)\n",
        "    ax[i, 0].plot([0, 1], [0, 1], '--k', lw=2, transform=ax[i, 0].transAxes)\n",
        "    mse_train = metrics.mean_squared_error(y_train, y_pred_train)\n",
        "    txt_train = f'MSE (Train) = {mse_train:.2e}'\n",
        "    text_train = ax[i, 0].text(0.45, 0.05, txt_train,\n",
        "                               transform=ax[i, 0].transAxes, fontsize=11, weight='bold',\n",
        "                               bbox=dict(facecolor='Whitesmoke', alpha=0.7))\n",
        "    ax[i, 0].set(ylabel='Predicted Values', xlabel='Actual Values')\n",
        "    ax[i, 0].set_title(f'{feature_set_labels[i]} (Train)', fontsize=14, weight='bold')\n",
        "    ax[i, 0].axis('equal')\n",
        "\n",
        "    # Test set\n",
        "    y_pred_test = reg.predict(X_test)\n",
        "    ax[i, 1].scatter(y_test, y_pred_test,\n",
        "                     facecolors='#9ac989', edgecolors='#217304', alpha=0.8)\n",
        "    ax[i, 1].plot([0, 1], [0, 1], '--k', lw=2, transform=ax[i, 1].transAxes)\n",
        "    mse_test = metrics.mean_squared_error(y_test, y_pred_test)\n",
        "    txt_test = f'MSE (Test) = {mse_test:.2e}'\n",
        "    text_test = ax[i, 1].text(0.45, 0.05, txt_test,\n",
        "                              transform=ax[i, 1].transAxes, fontsize=11, weight='bold',\n",
        "                              bbox=dict(facecolor='Whitesmoke', alpha=0.7))\n",
        "    ax[i, 1].set(ylabel='Predicted Values', xlabel='Actual Values')\n",
        "    ax[i, 1].set_title(f'{feature_set_labels[i]} (Test)', fontsize=14, weight='bold')\n",
        "    ax[i, 1].axis('equal')\n",
        "\n",
        "    # Print MSE values\n",
        "    txt = f'MSE (Train) = {mse_train:.3e}, MSE (Test) = {mse_test:.3e}'\n",
        "    print(feature_set_labels[i].replace('\\n',' '))\n",
        "    print(f'\\t{txt}')\n",
        "\n",
        "# Adjust layout and display the plots\n",
        "plt.tight_layout()\n",
        "sklearnex.unpatch_sklearn()"
      ],
      "metadata": {
        "id": "8OVzPT0N6_E_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Create DataFrames with feature importances\n",
        "# Create a DataFrame for feature importances using GradientBoostingRegressor\n",
        "importance_gb = pd.DataFrame({'Importance': reg_gb.feature_importances_ * 100}, index= X.columns)\n",
        "\n",
        "# Create a DataFrame for feature importances using XGBRegressor\n",
        "importance_xgb = pd.DataFrame({'Importance': reg_xgb.feature_importances_ * 100}, index= X.columns)\n",
        "\n",
        "# Create subplots\n",
        "# Create a figure with two vertically stacked subplots\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5), sharey=True)\n",
        "axes = axes.ravel()\n",
        "\n",
        "# Plot feature importance for GradientBoostingRegressor\n",
        "# Create a bar plot for feature importance in the first subplot\n",
        "axes[0].bar(importance_gb.index, importance_gb.Importance, color='#99f599', edgecolor='#006400', hatch=\"///\")\n",
        "axes[0].set_title('Feature Importance:\\nGradient Boosting Regressor', fontsize=13, weight='bold', color='DarkSlateGray')\n",
        "axes[0].set_ylim([0, 100])\n",
        "\n",
        "# Plot feature importance for XGBRegressor\n",
        "# Create a bar plot for feature importance in the second subplot\n",
        "axes[1].bar(importance_xgb.index, importance_xgb.Importance, color='#e9aaaa', edgecolor='#8B0000', hatch=\"\\\\\\\\\")\n",
        "axes[1].set_title('Feature Importance:\\nXGBoost Regressor', fontsize=12, weight='bold', color='DarkSlateGray')\n",
        "\n",
        "# Common settings for both subplots\n",
        "# Iterate through the axes and apply common settings\n",
        "for ax in axes:\n",
        "    ax.set_xlabel('Variable', weight='bold', color='MidnightBlue')\n",
        "    ax.tick_params(axis='x', rotation=90, color='DimGray')\n",
        "    ax.tick_params(axis='y', color='DimGray')\n",
        "    ax.spines[['top', 'right']].set_visible(False)\n",
        "    ax.spines[['bottom', 'left']].set_color('DimGray')\n",
        "    ax.set_ylabel('Importance (%)', weight='bold', color='MidnightBlue')\n",
        "    ax.grid(axis = 'x')\n",
        "\n",
        "# Remove the ylabel for the right plot\n",
        "axes[1].set_ylabel('')\n",
        "\n",
        "# Adjust layout and display the plots\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "ZJ0xGOGa8cjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge importance_gb and importance_xgb DataFrames\n",
        "merged_importance = pd.merge(importance_gb, importance_xgb, left_index=True, right_index=True,\n",
        "                              suffixes=(' (GB)', ' (XGB)'))\n",
        "merged_importance.columns = [x.replace('Importance', 'Feature Importance Percentage') for x in merged_importance.columns]\n",
        "# Display the merged DataFrame with background gradient\n",
        "display(merged_importance.style.format(precision=2).background_gradient(cmap='YlGn', axis=1, vmin = 0, vmax =50))"
      ],
      "metadata": {
        "id": "ChMuWgDq-oID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Boosting Classifier"
      ],
      "metadata": {
        "id": "kdk-1S6UBLD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from ucimlrepo import fetch_ucirepo\n",
        "except ImportError:\n",
        "    !pip3 install -U ucimlrepo\n",
        "    from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "rice_cammeo_and_osmancik = fetch_ucirepo(id=545)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = rice_cammeo_and_osmancik.data.features\n",
        "y = rice_cammeo_and_osmancik.data.targets\n",
        "\n",
        "# metadata\n",
        "print(rice_cammeo_and_osmancik.metadata)\n",
        "\n",
        "# variable information\n",
        "print(rice_cammeo_and_osmancik.variables)\n",
        "\n",
        "df = pd.concat([X, y], axis = 1)\n",
        "display(df)"
      ],
      "metadata": {
        "id": "xShsXBCsDmEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "codes, uniques = pd.factorize(y.Class)\n",
        "y = codes\n",
        "label_mapping = dict(zip(np.arange(len(uniques)), uniques))"
      ],
      "metadata": {
        "id": "b24_8fIbEotm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.25, random_state=0, stratify=y)\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def _dist_plot(ax, y, label_mapping=label_mapping, CM=plt.cm.tab20c.colors, title=False):\n",
        "    \"\"\"\n",
        "    Generate a pie chart illustrating the distribution of categories.\n",
        "\n",
        "    Parameters:\n",
        "    - ax: Axes object to plot on.\n",
        "    - y: Input data for which the distribution is to be visualized.\n",
        "    - label_mapping: Dictionary mapping category indices to labels.\n",
        "    - CM: Color map for the pie chart.\n",
        "    - title: Title for the plot. Set to False to omit.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    # Prepare data for the pie chart\n",
        "    df = pd.Series(y).value_counts().to_frame('Count')\n",
        "\n",
        "    # Create the pie chart\n",
        "    wedges, texts, autotexts = ax.pie(df['Count'],\n",
        "                                      labels=[label_mapping[i] for i in df.index],\n",
        "                                      autopct='%1.1f%%', startangle=140,\n",
        "                                      colors=CM,\n",
        "                                      explode=[0, 0.1],\n",
        "                                      shadow=True, wedgeprops={'edgecolor': 'whitesmoke'})\n",
        "    # Set title and ensure equal aspect ratio for a circular pie chart\n",
        "    if title:\n",
        "        _ = ax.set_title(title, fontsize=16, weight='bold')\n",
        "    _ = ax.axis('equal')\n",
        "\n",
        "    # Highlight the labels with annotations\n",
        "    for text, autotext in zip(texts, autotexts):\n",
        "        text.set_fontsize(12)\n",
        "        text.set_fontweight('bold')\n",
        "        autotext.set_fontsize(12)\n",
        "        autotext.set_fontweight('bold')\n",
        "\n",
        "\n",
        "# Create the figure and axes\n",
        "fig, ax = plt.subplots(1, 2, figsize=(9, 4.5))\n",
        "_dist_plot(ax[0], y_train, CM = plt.cm.Pastel1.colors)\n",
        "_ = ax[0].set_title(f'Train Set (Size = {len(X_train)})', fontsize=12, weight='bold', color='Green')\n",
        "_dist_plot(ax[1], y_test, CM = plt.cm.Pastel2.colors)\n",
        "_ = ax[1].set_title(f'Test Set (Size = {len(X_test)})', fontsize=12, weight='bold', color='Blue')\n",
        "_ = fig.suptitle('Distribution of Categories', fontsize=16, weight='bold')\n",
        "\n",
        "# Adjust layout and display the plot\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "mzvwN2r3BVOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import sklearnex\n",
        "sklearnex.patch_sklearn()\n",
        "# ------------------------------\n",
        "# Gradient Boosting Classifier\n",
        "# ------------------------------\n",
        "\n",
        "# Create a GradientBoostingClassifier\n",
        "gb_classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=0)\n",
        "\n",
        "# Fit the classifier to the training data\n",
        "gb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the classifier on the test data\n",
        "gb_accuracy = gb_classifier.score(X_train, y_train)\n",
        "print(f\"Gradient Boosting Classifier Accuracy (Train): {gb_accuracy:.4f}\")\n",
        "gb_accuracy = gb_classifier.score(X_test, y_test)\n",
        "print(f\"Gradient Boosting Classifier Accuracy (Test): {gb_accuracy:.4f}\")\n",
        "\n",
        "# ------------------------------\n",
        "# XGBoost Classifier\n",
        "# ------------------------------\n",
        "\n",
        "# Create an XGBClassifier\n",
        "xgb_classifier = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=0)\n",
        "\n",
        "# Fit the classifier to the training data\n",
        "xgb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Calculate accuracy using accuracy_score\n",
        "xgb_accuracy = xgb_classifier.score(X_train, y_train)\n",
        "print(f\"XGB Classifier Accuracy (Train): {xgb_accuracy:.4f}\")\n",
        "xgb_accuracy = xgb_classifier.score(X_test, y_test)\n",
        "print(f\"XGB Classifier Accuracy (Test): {xgb_accuracy:.4f}\")\n",
        "sklearnex.unpatch_sklearn()"
      ],
      "metadata": {
        "id": "Q79VjF75Cixl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "# Create subplots for a 2 by 2 plot\n",
        "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 6))\n",
        "\n",
        "axes = axes.ravel()\n",
        "# Confusion Matrix for GradientBoostingClassifier on Train Set\n",
        "ConfusionMatrixDisplay.from_estimator(gb_classifier, X_train, y_train, ax=axes[0], colorbar = False, cmap = 'Greens')\n",
        "axes[0].set_title(\"GBC Train Confusion Matrix\")\n",
        "\n",
        "# Confusion Matrix for GradientBoostingClassifier on Test Set\n",
        "ConfusionMatrixDisplay.from_estimator(gb_classifier, X_test, y_test, ax=axes[1], colorbar = False, cmap = 'Blues')\n",
        "axes[1].set_title(\"GBC Test Confusion Matrix\")\n",
        "\n",
        "# Confusion Matrix for XGBClassifier on Train Set\n",
        "ConfusionMatrixDisplay.from_estimator(xgb_classifier, X_train, y_train, ax=axes[2], colorbar = False, cmap = 'Greens')\n",
        "axes[2].set_title(\"XGBC Train Confusion Matrix\")\n",
        "\n",
        "# Confusion Matrix for XGBClassifier on Test Set\n",
        "ConfusionMatrixDisplay.from_estimator(xgb_classifier, X_test, y_test, ax=axes[3], colorbar = False, cmap = 'Blues')\n",
        "axes[3].set_title(\"XGBC Test Confusion Matrix\")\n",
        "\n",
        "for ax in axes:\n",
        "  ax.grid(False)\n",
        "  labels = [label_mapping[int(tick.get_text())] for tick in ax.get_xticklabels()]\n",
        "  ax.set_xticklabels(labels)\n",
        "  labels = [label_mapping[int(tick.get_text())] for tick in ax.get_yticklabels()]\n",
        "  ax.set_yticklabels(labels)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZJCBfk0iGqwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Create DataFrames with feature importances\n",
        "# Create a DataFrame for feature importances using GradientBoostingClassifier\n",
        "importance_gb = pd.DataFrame({'Importance': gb_classifier.feature_importances_ * 100}, index= X.columns)\n",
        "\n",
        "# Create a DataFrame for feature importances using XGBClassifier\n",
        "importance_xgb = pd.DataFrame({'Importance': xgb_classifier.feature_importances_ * 100}, index= X.columns)\n",
        "\n",
        "# Create subplots\n",
        "# Create a figure with two vertically stacked subplots\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5), sharey=True)\n",
        "axes = axes.ravel()\n",
        "\n",
        "# Plot feature importance for GradientBoostingClassifier\n",
        "# Create a bar plot for feature importance in the first subplot\n",
        "axes[0].bar(importance_gb.index, importance_gb.Importance, color='#99f599', edgecolor='#006400', hatch=\"///\")\n",
        "axes[0].set_title('Feature Importance:\\nGradient Boosting Classifier', fontsize=13, weight='bold', color='DarkSlateGray')\n",
        "axes[0].set_ylim([0, 100])\n",
        "\n",
        "# Plot feature importance for XGBClassifier\n",
        "# Create a bar plot for feature importance in the second subplot\n",
        "axes[1].bar(importance_xgb.index, importance_xgb.Importance, color='#e9aaaa', edgecolor='#8B0000', hatch=\"\\\\\\\\\")\n",
        "axes[1].set_title('Feature Importance:\\nXGBoost Classifier', fontsize=12, weight='bold', color='DarkSlateGray')\n",
        "\n",
        "# Common settings for both subplots\n",
        "# Iterate through the axes and apply common settings\n",
        "for ax in axes:\n",
        "    ax.set_xlabel('Variable', weight='bold', color='MidnightBlue')\n",
        "    ax.tick_params(axis='x', rotation=90, color='DimGray')\n",
        "    ax.tick_params(axis='y', color='DimGray')\n",
        "    ax.spines[['top', 'right']].set_visible(False)\n",
        "    ax.spines[['bottom', 'left']].set_color('DimGray')\n",
        "    ax.set_ylabel('Importance (%)', weight='bold', color='MidnightBlue')\n",
        "    ax.grid(axis = 'x')\n",
        "\n",
        "# Remove the ylabel for the right plot\n",
        "axes[1].set_ylabel('')\n",
        "\n",
        "# Adjust layout and display the plots\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "ENaLdfJ3ShdG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}