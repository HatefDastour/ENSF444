{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forests"
      ],
      "metadata": {
        "id": "c4go456S7pLq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Random Forest Regressor\n",
        "\n",
        "<font color='Blue'><b>Example</b></font>. The Auto MPG dataset retrieved from the [UCI Machine Learning Repository](http://archive.ics.uci.edu/dataset/9/auto+mpg)."
      ],
      "metadata": {
        "id": "CHMzPK9JGDeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from ucimlrepo import fetch_ucirepo\n",
        "except ImportError:\n",
        "    !pip3 install -U ucimlrepo\n",
        "    from ucimlrepo import fetch_ucirepo\n",
        "import numpy as np\n",
        "\n",
        "# fetch dataset\n",
        "auto_mpg = fetch_ucirepo(name = 'Auto MPG')\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = auto_mpg.data.features\n",
        "y = auto_mpg.data.targets\n",
        "\n",
        "# drop rows with missing values from X\n",
        "X = X.dropna(axis=0, how='any')\n",
        "\n",
        "# align X and y by index\n",
        "X, y = X.align(y, join='inner', axis=0)\n",
        "\n",
        "# ln(mpg)\n",
        "y = np.log(y['mpg'])\n",
        "y.name = 'ln(mpg)'\n",
        "print('X:')\n",
        "display(X)\n",
        "print('\\ny:')\n",
        "print(y)\n",
        "print('\\nInfo:')\n",
        "X.info()"
      ],
      "metadata": {
        "id": "70VcVB_FOSpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "\n",
        "# Create a DataFrame to display the sizes of the training and testing sets\n",
        "set_size_df = pd.DataFrame({'Size': [len(X_train), len(X_test)]}, index=['Train', 'Test'])\n",
        "display(set_size_df.T)"
      ],
      "metadata": {
        "id": "9YG9_8OtOV_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our goal is to create a Random Forest Regression model with certain specifications. In this setup, the model consists of four decision trees, each constrained to a maximum of three leaf nodes. The intention behind these parameter choices is to build an ensemble of decision trees that work together to make accurate regression predictions. The restriction on the number of nodes in each tree serves to manage the overall complexity of the model. The next step involves training the model using the provided training data, where `X_train` represents the features, and `y_train` represents the corresponding target values. Throughout this training process, the model evaluates the importance of each feature, contributing to a comprehensive understanding of its predictive capabilities."
      ],
      "metadata": {
        "id": "b8qQKAqUGB0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import metrics\n",
        "from sklearn import tree\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "\n",
        "# Set the custom style for plotting\n",
        "plt.style.use('https://raw.githubusercontent.com/HatefDastour/ENSF444/main/Files/mystyle.mplstyle')\n",
        "\n",
        "# Load the diabetes dataset\n",
        "diabetes_data = load_diabetes()\n",
        "X_diabetes = pd.DataFrame(diabetes_data.data, columns=diabetes_data.feature_names)\n",
        "y_diabetes = pd.Series(diabetes_data.target, name='target')\n",
        "\n",
        "# RandomForestRegressor with specified parameters\n",
        "rfr = RandomForestRegressor(n_estimators=4, random_state=0, max_leaf_nodes=3)\n",
        "rfr.fit(X_train, y_train)\n",
        "\n",
        "# Create subplots for each estimator\n",
        "fig, ax = plt.subplots(2, 2, figsize=(11, 8))\n",
        "ax = ax.ravel()\n",
        "\n",
        "# Initialize DataFrame for feature importance\n",
        "feat_importance_df = pd.DataFrame()\n",
        "\n",
        "# Iterate over estimators to plot trees and calculate MSE\n",
        "for i, (estimator, ax) in enumerate(zip(rfr.estimators_, ax), start=1):\n",
        "    tree.plot_tree(estimator, ax=ax, feature_names=X.columns.tolist(), filled=True,\n",
        "                   fontsize=11, rounded=True)\n",
        "\n",
        "    ax.set_title(f'Estimator {i}', fontsize=14, weight='bold')\n",
        "\n",
        "    # Calculate MSE for both training and test sets\n",
        "    mse_train = metrics.mean_squared_error(y_train, estimator.predict(X_train.values))\n",
        "    mse_test = metrics.mean_squared_error(y_test, estimator.predict(X_test.values))\n",
        "    txt = f'MSE (Train) = {mse_train:.5f}\\nMSE (Test) = {mse_test:.5f}'\n",
        "    print(f'\\nEstimator {i}:\\n'+ txt)\n",
        "\n",
        "    # Display MSE values on each subplot\n",
        "    text = ax.text(0.4, -0.05, txt,\n",
        "                  transform=ax.transAxes, fontsize=11, weight='bold',\n",
        "                  bbox=dict(facecolor='#dfc8f0', alpha=0.7))\n",
        "\n",
        "    # Create DataFrame with feature importances for each estimator\n",
        "    df_temp = pd.DataFrame({f'Estimator {i}': 100*estimator.feature_importances_}, index=X.columns)\n",
        "    feat_importance_df = pd.concat([feat_importance_df, df_temp], axis=1)\n",
        "\n",
        "# Ensure tight layout for subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Apply background gradient to the DataFrame and round importance values to 2 decimal places\n",
        "styled_importance = feat_importance_df.style.\\\n",
        "                    background_gradient(cmap='Reds', axis=1, vmin=0, vmax=100).format(precision=2)\n",
        "\n",
        "# Display the styled DataFrame\n",
        "print('\\nFeature Importance:')\n",
        "display(styled_importance)"
      ],
      "metadata": {
        "id": "l5CCzl1T74aC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxWeo9V27dWk"
      },
      "outputs": [],
      "source": [
        "# Calculate MSE for both training and test sets\n",
        "mse_train = metrics.mean_squared_error(y_train, rfr.predict(X_train))\n",
        "mse_test = metrics.mean_squared_error(y_test, rfr.predict(X_test))\n",
        "txt = f'MSE (Train) = {mse_train:.5f}\\nMSE (Test) = {mse_test:.5f}'\n",
        "print(txt)\n",
        "\n",
        "# Create a DataFrame to store feature importances\n",
        "Importance = pd.DataFrame({'Importance': 100*rfr.feature_importances_}, index=X.columns)\n",
        "\n",
        "# Apply a background gradient to the DataFrame and round importance values to 2 decimal places\n",
        "styled_importance = Importance.style.background_gradient(cmap='Oranges',\n",
        "                                                         subset=['Importance']).format({'Importance': '{:.2f}'})\n",
        "\n",
        "# Display the styled DataFrame\n",
        "display(styled_importance)\n",
        "\n",
        "# Create a bar plot to visualize feature importances\n",
        "fig, ax = plt.subplots(1, 1, figsize=(6, 5))\n",
        "bars = ax.bar(Importance.index, Importance.Importance,\n",
        "              color='#f9cb9c', edgecolor='#cc0000', hatch=\"\\\\\\\\\", lw=2, zorder=2)\n",
        "\n",
        "# Set plot labels and title\n",
        "ax.set_xlabel('Features', fontsize=12, weight='bold', color='#191970')\n",
        "ax.set_ylabel('Importance', fontsize=12, weight='bold', color='#191970')\n",
        "ax.set_title('Feature Importance', y=1.05,\n",
        "             fontsize=16, weight='bold', color='#2F4F4F')\n",
        "\n",
        "# Set y-axis limits and adjust tick parameters\n",
        "ax.set_ylim([0, 80])\n",
        "ax.tick_params(axis='x', rotation=45, labelsize=12, color='#696969')\n",
        "ax.tick_params(axis='y', labelsize=12, color='#696969')\n",
        "\n",
        "# Customize plot aesthetics\n",
        "ax.spines[['top', 'right']].set_visible(False)\n",
        "ax.spines[['bottom', 'left']].set_color('#696969')\n",
        "ax.grid(axis='x')\n",
        "\n",
        "# Ensure a tight layout for better visualization\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictions"
      ],
      "metadata": {
        "id": "8m_0ivfUit1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a sample from the test set for prediction\n",
        "sample_x_test = X_test.iloc[-2:-1]\n",
        "display(sample_x_test)\n",
        "\n",
        "# Initialize a list to store individual predictions from each estimator\n",
        "pred_list = []\n",
        "\n",
        "# Iterate over estimators to make predictions and display individual results\n",
        "for i, estimator in enumerate(rfr.estimators_, start=1):\n",
        "    pred_ = estimator.predict(sample_x_test.values)[0]\n",
        "    pred_list.append(pred_)\n",
        "    print(f'Prediction from Estimator {i} = {pred_:.6f}')\n",
        "\n",
        "# Display the mean prediction from all estimators and the prediction from the RandomForestRegressor\n",
        "print(f'\\nMean Prediction from All Estimators = {np.mean(pred_list):.6f}')\n",
        "print(f'\\nPrediction from RFR = {rfr.predict(sample_x_test)[0]:.6f}')"
      ],
      "metadata": {
        "id": "19FzoEVdi3qc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Estimators"
      ],
      "metadata": {
        "id": "fe0UXNPmZp2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, we are assessing the performance of Random Forest Regressors with varying configurations of the maximum number of leaf nodes (`max_leaf_nodes`) and the number of estimators (`n_estimators`). The experiment involves training the models on a given dataset and recording the mean squared errors on both the training and test sets across different hyperparameter settings."
      ],
      "metadata": {
        "id": "d3h_GQWdrmPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import OrderedDict\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Define the ensemble regressors with specific parameters\n",
        "ensemble_regrs = [(\"RandomForestRegressor, max_leaf_nodes=5\",\n",
        "                    RandomForestRegressor(random_state=0, max_leaf_nodes=5),\n",
        "                   ),\n",
        "                  (\"RandomForestRegressor, max_leaf_nodes=7\",\n",
        "                    RandomForestRegressor(random_state=0, max_leaf_nodes=7),\n",
        "                   ),\n",
        "                  (\"RandomForestRegressor, max_leaf_nodes=11\",\n",
        "                    RandomForestRegressor(random_state=0, max_leaf_nodes=11),\n",
        "                   )\n",
        "]\n",
        "\n",
        "# Initialize dictionaries to store error rates and test mean squared errors\n",
        "train_error = OrderedDict((label, []) for label, _ in ensemble_regrs)\n",
        "test_error = OrderedDict((label, []) for label, _ in ensemble_regrs)\n",
        "\n",
        "# Define the range of `n_estimators` values to explore\n",
        "min_estimators = 15\n",
        "max_estimators = 120\n",
        "\n",
        "# Iterate over ensemble regressors and `n_estimators` values\n",
        "for label, regr in ensemble_regrs:\n",
        "    for i in range(min_estimators, max_estimators + 1, 5):\n",
        "        # Set the number of estimators\n",
        "        regr.set_params(n_estimators=i)\n",
        "\n",
        "        # Fit the model on the training data\n",
        "        regr.fit(X_train, y_train)\n",
        "\n",
        "        # Record the train mean squared error for each `n_estimators=i` setting\n",
        "        train_pred = regr.predict(X_train)\n",
        "        train_mse = mean_squared_error(y_train, train_pred)\n",
        "        train_error[label].append((i, train_mse))\n",
        "\n",
        "        # Record the test mean squared error for each `n_estimators=i` setting\n",
        "        test_pred = regr.predict(X_test)\n",
        "        test_mse = mean_squared_error(y_test, test_pred)\n",
        "        test_error[label].append((i, test_mse))"
      ],
      "metadata": {
        "id": "2j-IgfAwZrrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create subplots using fig and ax, sharing x-axis\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(11, 6), sharex=True)\n",
        "\n",
        "# Plot training mean squared errors for each ensemble regressor\n",
        "for label, regr_err in train_error.items():\n",
        "    xs, ys = zip(*regr_err)\n",
        "    ax1.plot(xs, ys, lw=2, label=label)\n",
        "\n",
        "# Plot test mean squared errors for each ensemble regressor\n",
        "for label, regr_err in test_error.items():\n",
        "    xs, ys = zip(*regr_err)\n",
        "    ax2.plot(xs, ys, lw=2, label=label)\n",
        "\n",
        "# Set y-axis to logarithmic scale\n",
        "ax1.set_yscale('log')\n",
        "ax2.set_yscale('log')\n",
        "\n",
        "# Set plot parameters for the training set plot\n",
        "ax1.set_xlim(min_estimators, max_estimators)\n",
        "ax1.set_ylabel(\"Mean Squared Error\\n(Train Set)\")\n",
        "\n",
        "# Set plot parameters for the test set plot\n",
        "ax2.set_xlim(min_estimators, max_estimators)\n",
        "ax2.set_xlabel(\"n_estimators\")\n",
        "ax2.set_ylabel(\"Mean Squared Error\\n(Test Set)\")\n",
        "\n",
        "# Combine legends for both plots\n",
        "ax1.legend(loc=\"upper left\", bbox_to_anchor=(0.56, 1.35))\n",
        "\n",
        "# Ensure a tight layout for better visualization\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "aPuoDD7gZ16e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest Classifier"
      ],
      "metadata": {
        "id": "bS0qexHSjgTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.inspection import DecisionBoundaryDisplay\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "\n",
        "# Use a custom style for the plot (adjust the path to your style file)\n",
        "plt.style.use('https://raw.githubusercontent.com/HatefDastour/ENSF444/main/Files/mystyle.mplstyle')\n",
        "\n",
        "# Load the wine dataset\n",
        "wine_data = load_wine()\n",
        "X, y = wine_data.data, wine_data.target\n",
        "feature_names = wine_data.feature_names\n",
        "\n",
        "# Create a DataFrame for visualization\n",
        "df = pd.DataFrame(data=X, columns=feature_names)\n",
        "df['class'] = y\n",
        "display(df)\n",
        "\n",
        "# Display the dataset description\n",
        "print(wine_data.DESCR)"
      ],
      "metadata": {
        "id": "FYWznuHEy5gY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
        "\n",
        "# Initialize RandomForestClassifier with specified parameters\n",
        "rfc = RandomForestClassifier(n_estimators=4, random_state=0, max_leaf_nodes=3)\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "# Display accuracy score for each estimator\n",
        "for i, estimator in enumerate(rfc.estimators_, start=1):\n",
        "    accuracy_train = metrics.accuracy_score(estimator.predict(X_train), y_train)\n",
        "    accuracy_test = metrics.accuracy_score(estimator.predict(X_test), y_test)\n",
        "    txt = f'Estimator {i}: Accuracy (Train) = {accuracy_train:.4f}, Accuracy (Test) = {accuracy_test:.4f}'\n",
        "    print(txt)"
      ],
      "metadata": {
        "id": "ui8X5V4dvZsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.tree import plot_tree\n",
        "\n",
        "# Plot decision trees in a 2 by 2 layout\n",
        "fig, axes = plt.subplots(2, 2, figsize=(13, 9))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i, (estimator, ax) in enumerate(zip(rfc.estimators_, axes), start=1):\n",
        "    # Plot decision tree\n",
        "    plot_tree(estimator, filled=False, feature_names=feature_names, class_names= wine_data.target_names,\n",
        "              ax=ax, fontsize=11, impurity=True, rounded=True, proportion= True)\n",
        "    ax.set_title(f'Estimator {i}', fontsize=14, weight='bold')\n",
        "\n",
        "# Add a super title for the entire figure\n",
        "fig.suptitle('Decision Trees', fontsize=16, weight='bold')\n",
        "\n",
        "# Adjust layout and display the plots\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "P6B2gRopn87t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_train = metrics.accuracy_score(y_train, rfc.predict(X_train))\n",
        "accuracy_test = metrics.accuracy_score(y_test, rfc.predict(X_test))\n",
        "txt = f'Accuracy Score(Train) = {accuracy_train:.5f}\\nAccuracy Score(Test) = {accuracy_test:.5f}'\n",
        "print(txt)\n",
        "\n",
        "# Create a DataFrame to store feature importances\n",
        "Importance = pd.DataFrame({'Importance': 100*rfc.feature_importances_}, index = feature_names)\n",
        "\n",
        "# Apply a background gradient to the DataFrame and round importance values to 2 decimal places\n",
        "styled_importance = Importance.style.background_gradient(cmap='Oranges',\n",
        "                                                         subset=['Importance']).format({'Importance': '{:.2f}'})\n",
        "\n",
        "# Display the styled DataFrame\n",
        "display(styled_importance)\n",
        "\n",
        "# Create a bar plot to visualize feature importances\n",
        "fig, ax = plt.subplots(1, 1, figsize=(6, 5))\n",
        "bars = ax.bar(Importance.index, Importance.Importance,\n",
        "              color='#f9cb9c', edgecolor='#cc0000', hatch=\"\\\\\\\\\", lw=2, zorder = 2)\n",
        "\n",
        "# Set plot labels and title\n",
        "ax.set_xlabel('Features', fontsize=12, weight='bold', color='#191970')\n",
        "ax.set_ylabel('Importance', fontsize=12, weight='bold', color='#191970')\n",
        "ax.set_title('Feature Importance', y = 1.05,\n",
        "             fontsize=16, weight='bold', color='#2F4F4F')\n",
        "\n",
        "# Set y-axis limits and adjust tick parameters\n",
        "ax.set_ylim([0, 40])\n",
        "ax.tick_params(axis='x', rotation=90, labelsize=12, color='#696969')\n",
        "ax.tick_params(axis='y', labelsize=12, color='#696969')\n",
        "\n",
        "# Customize plot aesthetics\n",
        "ax.spines[['top', 'right']].set_visible(False)\n",
        "ax.spines[['bottom', 'left']].set_color('#696969')\n",
        "ax.grid(axis='x')\n",
        "\n",
        "# Ensure a tight layout for better visualization\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "kjJeXylzunAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.inspection import DecisionBoundaryDisplay\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "\n",
        "# Use a custom style for the plot (adjust the path to your style file)\n",
        "plt.style.use('https://raw.githubusercontent.com/HatefDastour/ENSF444/main/Files/mystyle.mplstyle')\n",
        "\n",
        "def plot_cm(model, X_train, X_test, y_train, y_test, class_names, figsize=(12, 8), title='Confusion Matrices'):\n",
        "    # Create a figure and axes for displaying confusion matrices side by side\n",
        "    fig, ax = plt.subplots(1, 2, figsize=figsize)\n",
        "\n",
        "    datasets = [(X_train, y_train, 'Train'), (X_test, y_test, 'Test')]\n",
        "\n",
        "    for i in range(2):\n",
        "        X, y, dataset_name = datasets[i]\n",
        "\n",
        "        # Compute confusion matrix for the dataset predictions\n",
        "        cm = confusion_matrix(y, model.predict(X))\n",
        "\n",
        "        # Create a ConfusionMatrixDisplay and plot it on the respective axis\n",
        "        cm_display = ConfusionMatrixDisplay(cm, display_labels=class_names) \\\n",
        "            .plot(ax=ax[i],\n",
        "                  im_kw=dict(cmap='Greens' if dataset_name == 'Train' else 'Blues'),\n",
        "                  text_kw={\"size\": 16}, colorbar=False)\n",
        "        ax[i].set_title(f'{dataset_name} Data')\n",
        "        ax[i].grid(False)\n",
        "\n",
        "    # Rotate x-axis labels\n",
        "    for ax_ in ax:\n",
        "        ax_.set_xticklabels(ax_.get_xticklabels(), rotation=45, ha='right')\n",
        "\n",
        "    # Add a super title for the entire figure\n",
        "    fig.suptitle(title, fontsize=16, weight='bold')\n",
        "\n",
        "    # Adjust the layout for better spacing\n",
        "    plt.tight_layout()\n",
        "\n",
        "# Assuming rfc and axes are defined before this point\n",
        "for i, (estimator, ax) in enumerate(zip(rfc.estimators_, axes), start=1):\n",
        "    plot_cm(estimator, X_train, X_test, y_train, y_test, class_names=wine_data.target_names,\n",
        "            title=f'Confusion Matrices for Estimator {i}', figsize=(6, 3))"
      ],
      "metadata": {
        "id": "-GGmApQRpkjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_cm(rfc, X_train, X_test, y_train, y_test,\n",
        "        class_names = wine_data.target_names, figsize=(7, 4), title='Confusion Matrices for RFC')"
      ],
      "metadata": {
        "id": "SRy5i6PC3zBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictions"
      ],
      "metadata": {
        "id": "fiSi-a_kszXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a sample from the test set for prediction\n",
        "sample_x_test = X_test[-2:-1, :]\n",
        "display(pd.DataFrame(sample_x_test, columns=feature_names))\n",
        "\n",
        "# Initialize a list to store individual predictions from each estimator\n",
        "pred_list = []\n",
        "\n",
        "# Function to find the most frequent item in a list\n",
        "def most_frequent_item(lst):\n",
        "    unique_elements, counts = np.unique(lst, return_counts=True)\n",
        "    index_of_max_frequency = np.argmax(counts)\n",
        "    most_frequent_string = unique_elements[index_of_max_frequency]\n",
        "    return most_frequent_string\n",
        "\n",
        "# Iterate over estimators to make predictions and display individual results\n",
        "for i, estimator in enumerate(rfc.estimators_, start=1):\n",
        "    pred_ = estimator.predict(sample_x_test)[0]\n",
        "    pred_ = wine_data.target_names[int(pred_)]\n",
        "    pred_list.append(pred_)\n",
        "    print(f'Prediction from Estimator {i} = {pred_}')\n",
        "\n",
        "# Display the mode prediction from all estimators\n",
        "print(f'\\nMode Prediction from All Estimators = {most_frequent_item(pred_list)}')\n",
        "\n",
        "# Make a prediction using the RandomForestClassifier and display the result\n",
        "pred_ = rfc.predict(sample_x_test)[0]\n",
        "pred_ = wine_data.target_names[int(pred_)]\n",
        "print(f'\\nPrediction from RFC = {pred_}')"
      ],
      "metadata": {
        "id": "wwW2YAXPp56w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}